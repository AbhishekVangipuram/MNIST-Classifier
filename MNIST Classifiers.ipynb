{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./datasets\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./datasets\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./datasets\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%C:\\Users\\abhiv\\.conda\\envs\\test_env\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./datasets\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4), (0.2))\n",
    "])\n",
    "\n",
    "# MNIST has 70,000 images\n",
    "# We use 60,000 images. At test time, we will use the other 10,000 images.\n",
    "NUM_TRAIN = 57000\n",
    "\n",
    "mnist_train = dset.MNIST('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(mnist_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "mnist_val = dset.MNIST('./datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(mnist_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 60000)))\n",
    "\n",
    "mnist_test = dset.MNIST('./datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(mnist_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(32,64,kernel_size=3, padding=1),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)), # (N, 64, 14, 14)\n",
    "    \n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)), # (N, 64, 7, 7)\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64*7*7, 64*4*4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64*4*4, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,10),\n",
    "    nn.Dropout(0.3)    \n",
    ").to(device)\n",
    "\n",
    "conv_optim = optim.Adam(model_conv.parameters(), weight_decay = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, 10)\n",
    ").to(device=device, dtype=dtype)\n",
    "\n",
    "fc_optim = optim.Adam(model_fc.parameters(), weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print(f'Got {num_correct} / {num_samples} correct (%.2f)' % (100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loadert, loaderv, epochs=1, print_every=100):\n",
    "    for e in range(epochs):\n",
    "        print(f\"----------  Epoch {e}  ----------\\n\")\n",
    "        for t, (x,y) in enumerate(loadert):\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print(f\"Iteration {t}: Loss = {loss.item()}\")\n",
    "                check_accuracy(loaderv, model)\n",
    "                print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Epoch 0  ----------\n",
      "\n",
      "Iteration 0: Loss = 2.334533929824829\n",
      "Checking accuracy on validation set\n",
      "Got 589 / 3000 correct (19.63)\n",
      "\n",
      "Iteration 500: Loss = 0.17414768040180206\n",
      "Checking accuracy on validation set\n",
      "Got 2892 / 3000 correct (96.40)\n",
      "\n",
      "----------  Epoch 1  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.238621324300766\n",
      "Checking accuracy on validation set\n",
      "Got 2909 / 3000 correct (96.97)\n",
      "\n",
      "Iteration 500: Loss = 0.10675705224275589\n",
      "Checking accuracy on validation set\n",
      "Got 2911 / 3000 correct (97.03)\n",
      "\n",
      "----------  Epoch 2  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.13637706637382507\n",
      "Checking accuracy on validation set\n",
      "Got 2920 / 3000 correct (97.33)\n",
      "\n",
      "Iteration 500: Loss = 0.12428975105285645\n",
      "Checking accuracy on validation set\n",
      "Got 2906 / 3000 correct (96.87)\n",
      "\n",
      "----------  Epoch 3  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.0475778728723526\n",
      "Checking accuracy on validation set\n",
      "Got 2941 / 3000 correct (98.03)\n",
      "\n",
      "Iteration 500: Loss = 0.09662456065416336\n",
      "Checking accuracy on validation set\n",
      "Got 2920 / 3000 correct (97.33)\n",
      "\n",
      "----------  Epoch 4  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.16541297733783722\n",
      "Checking accuracy on validation set\n",
      "Got 2910 / 3000 correct (97.00)\n",
      "\n",
      "Iteration 500: Loss = 0.020284563302993774\n",
      "Checking accuracy on validation set\n",
      "Got 2922 / 3000 correct (97.40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model_fc, fc_optim, loader_train, loader_val, epochs=5, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 9534 / 10000 correct (95.34)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(loader_test, model_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Epoch 0  ----------\n",
      "\n",
      "Iteration 0: Loss = 2.317458152770996\n",
      "Checking accuracy on validation set\n",
      "Got 309 / 3000 correct (10.30)\n",
      "\n",
      "Iteration 500: Loss = 0.06568978726863861\n",
      "Checking accuracy on validation set\n",
      "Got 2914 / 3000 correct (97.13)\n",
      "\n",
      "----------  Epoch 1  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.08501437306404114\n",
      "Checking accuracy on validation set\n",
      "Got 2936 / 3000 correct (97.87)\n",
      "\n",
      "Iteration 500: Loss = 0.04274098202586174\n",
      "Checking accuracy on validation set\n",
      "Got 2921 / 3000 correct (97.37)\n",
      "\n",
      "----------  Epoch 2  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.07485563308000565\n",
      "Checking accuracy on validation set\n",
      "Got 2937 / 3000 correct (97.90)\n",
      "\n",
      "Iteration 500: Loss = 0.06528503447771072\n",
      "Checking accuracy on validation set\n",
      "Got 2948 / 3000 correct (98.27)\n",
      "\n",
      "----------  Epoch 3  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.03686854615807533\n",
      "Checking accuracy on validation set\n",
      "Got 2944 / 3000 correct (98.13)\n",
      "\n",
      "Iteration 500: Loss = 0.08982988446950912\n",
      "Checking accuracy on validation set\n",
      "Got 2948 / 3000 correct (98.27)\n",
      "\n",
      "----------  Epoch 4  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.10014572739601135\n",
      "Checking accuracy on validation set\n",
      "Got 2939 / 3000 correct (97.97)\n",
      "\n",
      "Iteration 500: Loss = 0.06261036545038223\n",
      "Checking accuracy on validation set\n",
      "Got 2952 / 3000 correct (98.40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model_conv, conv_optim, loader_train, loader_val, epochs=5, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 9826 / 10000 correct (98.26)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(loader_test, model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./datasets\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./datasets\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./datasets\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./datasets\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./datasets\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./datasets\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./datasets\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./datasets\\FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4), (0.2))\n",
    "])\n",
    "\n",
    "# Fashion MNIST has 70,000 images\n",
    "# We use 60,000 images. At test time, we will use the remaining 10,000 images.\n",
    "NUM_TRAIN = 57000\n",
    "\n",
    "fash_train = dset.FashionMNIST('./datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(fash_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "fash_val = dset.FashionMNIST('./datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(fash_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 60000)))\n",
    "\n",
    "fash_test = dset.FashionMNIST('./datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(fash_test, batch_size=64)\n",
    "\n",
    "model_fc.reset_parameters()\n",
    "model_conv.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Epoch 0  ----------\n",
      "\n",
      "Iteration 0: Loss = 6.890028476715088\n",
      "Checking accuracy on validation set\n",
      "Got 166 / 3000 correct (5.53)\n",
      "\n",
      "Iteration 500: Loss = 0.6413515210151672\n",
      "Checking accuracy on validation set\n",
      "Got 2353 / 3000 correct (78.43)\n",
      "\n",
      "----------  Epoch 1  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.6066540479660034\n",
      "Checking accuracy on validation set\n",
      "Got 2436 / 3000 correct (81.20)\n",
      "\n",
      "Iteration 500: Loss = 0.40940040349960327\n",
      "Checking accuracy on validation set\n",
      "Got 2486 / 3000 correct (82.87)\n",
      "\n",
      "----------  Epoch 2  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.43081191182136536\n",
      "Checking accuracy on validation set\n",
      "Got 2530 / 3000 correct (84.33)\n",
      "\n",
      "Iteration 500: Loss = 0.38758134841918945\n",
      "Checking accuracy on validation set\n",
      "Got 2545 / 3000 correct (84.83)\n",
      "\n",
      "----------  Epoch 3  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.373351126909256\n",
      "Checking accuracy on validation set\n",
      "Got 2572 / 3000 correct (85.73)\n",
      "\n",
      "Iteration 500: Loss = 0.4051193296909332\n",
      "Checking accuracy on validation set\n",
      "Got 2563 / 3000 correct (85.43)\n",
      "\n",
      "----------  Epoch 4  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.3670084774494171\n",
      "Checking accuracy on validation set\n",
      "Got 2586 / 3000 correct (86.20)\n",
      "\n",
      "Iteration 500: Loss = 0.44937169551849365\n",
      "Checking accuracy on validation set\n",
      "Got 2582 / 3000 correct (86.07)\n",
      "\n",
      "----------  Epoch 5  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.34993648529052734\n",
      "Checking accuracy on validation set\n",
      "Got 2569 / 3000 correct (85.63)\n",
      "\n",
      "Iteration 500: Loss = 0.32585224509239197\n",
      "Checking accuracy on validation set\n",
      "Got 2597 / 3000 correct (86.57)\n",
      "\n",
      "----------  Epoch 6  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.31283169984817505\n",
      "Checking accuracy on validation set\n",
      "Got 2604 / 3000 correct (86.80)\n",
      "\n",
      "Iteration 500: Loss = 0.27309226989746094\n",
      "Checking accuracy on validation set\n",
      "Got 2598 / 3000 correct (86.60)\n",
      "\n",
      "----------  Epoch 7  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.37388500571250916\n",
      "Checking accuracy on validation set\n",
      "Got 2600 / 3000 correct (86.67)\n",
      "\n",
      "Iteration 500: Loss = 0.4780305027961731\n",
      "Checking accuracy on validation set\n",
      "Got 2611 / 3000 correct (87.03)\n",
      "\n",
      "----------  Epoch 8  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.46765226125717163\n",
      "Checking accuracy on validation set\n",
      "Got 2613 / 3000 correct (87.10)\n",
      "\n",
      "Iteration 500: Loss = 0.24051961302757263\n",
      "Checking accuracy on validation set\n",
      "Got 2603 / 3000 correct (86.77)\n",
      "\n",
      "----------  Epoch 9  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.2998061180114746\n",
      "Checking accuracy on validation set\n",
      "Got 2617 / 3000 correct (87.23)\n",
      "\n",
      "Iteration 500: Loss = 0.4291914999485016\n",
      "Checking accuracy on validation set\n",
      "Got 2620 / 3000 correct (87.33)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc_optim = optim.SGD(model_fc.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "train_model(model_fc, fc_optim, loader_train, loader_val, epochs=10, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 8631 / 10000 correct (86.31)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(loader_test, model_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Epoch 0  ----------\n",
      "\n",
      "Iteration 0: Loss = 3.7345099449157715\n",
      "Checking accuracy on validation set\n",
      "Got 209 / 3000 correct (6.97)\n",
      "\n",
      "Iteration 500: Loss = 0.6412071585655212\n",
      "Checking accuracy on validation set\n",
      "Got 2371 / 3000 correct (79.03)\n",
      "\n",
      "----------  Epoch 1  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.45955002307891846\n",
      "Checking accuracy on validation set\n",
      "Got 2489 / 3000 correct (82.97)\n",
      "\n",
      "Iteration 500: Loss = 0.3712809979915619\n",
      "Checking accuracy on validation set\n",
      "Got 2535 / 3000 correct (84.50)\n",
      "\n",
      "----------  Epoch 2  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.31323274970054626\n",
      "Checking accuracy on validation set\n",
      "Got 2522 / 3000 correct (84.07)\n",
      "\n",
      "Iteration 500: Loss = 0.3540203273296356\n",
      "Checking accuracy on validation set\n",
      "Got 2586 / 3000 correct (86.20)\n",
      "\n",
      "----------  Epoch 3  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.4157051742076874\n",
      "Checking accuracy on validation set\n",
      "Got 2592 / 3000 correct (86.40)\n",
      "\n",
      "Iteration 500: Loss = 0.30157551169395447\n",
      "Checking accuracy on validation set\n",
      "Got 2607 / 3000 correct (86.90)\n",
      "\n",
      "----------  Epoch 4  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.3328908681869507\n",
      "Checking accuracy on validation set\n",
      "Got 2610 / 3000 correct (87.00)\n",
      "\n",
      "Iteration 500: Loss = 0.41546952724456787\n",
      "Checking accuracy on validation set\n",
      "Got 2625 / 3000 correct (87.50)\n",
      "\n",
      "----------  Epoch 5  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.3752380907535553\n",
      "Checking accuracy on validation set\n",
      "Got 2641 / 3000 correct (88.03)\n",
      "\n",
      "Iteration 500: Loss = 0.4044305086135864\n",
      "Checking accuracy on validation set\n",
      "Got 2655 / 3000 correct (88.50)\n",
      "\n",
      "----------  Epoch 6  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.28515514731407166\n",
      "Checking accuracy on validation set\n",
      "Got 2669 / 3000 correct (88.97)\n",
      "\n",
      "Iteration 500: Loss = 0.35388481616973877\n",
      "Checking accuracy on validation set\n",
      "Got 2671 / 3000 correct (89.03)\n",
      "\n",
      "----------  Epoch 7  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.2848382890224457\n",
      "Checking accuracy on validation set\n",
      "Got 2672 / 3000 correct (89.07)\n",
      "\n",
      "Iteration 500: Loss = 0.30593863129615784\n",
      "Checking accuracy on validation set\n",
      "Got 2664 / 3000 correct (88.80)\n",
      "\n",
      "----------  Epoch 8  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.23922212421894073\n",
      "Checking accuracy on validation set\n",
      "Got 2679 / 3000 correct (89.30)\n",
      "\n",
      "Iteration 500: Loss = 0.1998194307088852\n",
      "Checking accuracy on validation set\n",
      "Got 2692 / 3000 correct (89.73)\n",
      "\n",
      "----------  Epoch 9  ----------\n",
      "\n",
      "Iteration 0: Loss = 0.2297152876853943\n",
      "Checking accuracy on validation set\n",
      "Got 2644 / 3000 correct (88.13)\n",
      "\n",
      "Iteration 500: Loss = 0.21926383674144745\n",
      "Checking accuracy on validation set\n",
      "Got 2679 / 3000 correct (89.30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv_optim = optim.SGD(model_conv.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "train_model(model_conv, conv_optim, loader_train, loader_val, epochs=10, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 8852 / 10000 correct (88.52)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(loader_test, model_conv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
